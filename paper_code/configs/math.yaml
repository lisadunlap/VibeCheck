# project: VibeCheck-MATH-New
# wandb: False # Set to True to log to Weights and Biases
# num_samples: 100
# dummy_eval: False
# oz: False
# group_column: False
# test: False
# save_dir: pipeline_results
# data_path: data/helm/algrbra_llam_45_gpt_4o.csv
# # test_data_path: data/helm/math_gpt_test.csv
# # data_path: data/benchmark/arena_friendly_and_cold_smaller.csv
# k: 5
# batch_size: 50
# num_axes_generated: 10
# num_eval: 10
# embedding_model: text-embedding-3-small
# seed: 42
# cluster_method: hierarchical
# ranker: RelativeRankerFixed
# sampler: Sampler
# reducer: AxisReducer
# proposer: LLMProposerFixed
# num_topic_clusters: 5
# # heldout_percentage: 0.75
# proposer_batch_size: 5
# judges: [gpt-4o-mini]
# # judges: [gpt-4o]
# models: ['gpt-4o', 'llama-405b']
# eval_only: False
# num_proposal_samples: 20
# new_prompt: True
# axes: False
# # axes: [
# # 'Adherence to Problem Constraints and Approach Consistency: High: Follows guidelines closely, logical sequence Low: Ignores guidelines, illogical progression', 
# # 'Brevity: High: Succinct, no extra information Low: Wordy, includes unnecessary details', 
# # # 'Consistency and Formatting: High: Uniform approach, clean presentation Low: Inconsistent, irregular formatting', 
# # 'Creativity and Engagement: High: Imaginative, maintains interest Low: Predictable, dull', 
# # # 'Error Handling and Robustness to Ambiguity: High: Considers potential errors and ambiguities Low: Overlooks errors and ambiguities', 
# # "Confidence in Results: High: Statements are confident and assertive. Low: Shows uncertainty or hesitance.",
# # 'Formality and Technicality: High: Professional, uses technical terms appropriately Low: Casual, simple language', 
# # # 'Mathematical Detail and Rigor: High: Includes correct notation, detailed steps Low: Generalized, lacks detail', 
# # 'Mathematical Notation Use: High: Uses extensive notation and formal equations. Low: Relies on minimal notation and equations.',
# # 'Readability and Accessibility: High: Easy to understand, clear layout Low: Difficult to follow, cluttered', 
# # 'Specificity and Detail Orientation: High: Specific, covers all steps Low: Generalized, skips important steps'
# # ]

# # - Conceptual Illustration: High: Provides detailed concept clarification. Low: Offers limited conceptual clarification.
# # - Diagram Integration: High: Diagrams well incorporated and referenced. Low: Diagrams not integrated or referenced.
# # - Extra Explanation: High: Gives additional context and explanations. Low: Sticks to necessary explanations only.
# # - Logical Flow: High: Follows a clear, stepwise progression. Low: Omits steps, making the logic harder to follow.
# # - Problem Interpretation Variability: High: Adopts conventional interpretations. Low: Prefers unconventional interpretations.
# # - Confidence in Results: High: Statements are confident and assertive. Low: Shows uncertainty or hesitance.
# # - Mathematical Rigor: High: Uses correct methods with careful application. Low: Prone to errors or incorrect methods.
# # - Precision: High: Answers are precise with necessary context. Low: Provides bare outputs without context.
# # - Mathematical Notation Use: High: Uses extensive notation and formal equations. Low: Relies on minimal notation and equations.
# # - Detail Elaboration: High: Elaborates with thorough, step-by-step details. Low: Offers brief explanations with minimal steps.
# # - Consistency: High: Maintains logical cohesion and consistent methods. Low: Shows contradictions or inconsistent approaches.

# new_sample: True

# early_stopping: True
# topic_based_rubric_example: False
# early_stopping_threshold: 0.2

# # models
# rubric_generation_model: "gpt-4o"
# proposer_model: "gpt-4o"
project: VibeCheck-CoTMath
wandb: False # Set to True to log to Weights and Biases
num_samples: False
dummy_eval: False
oz: False
group_column: False
output_name: final_eval
test: False
data_path: data/math/math_cot_train.csv
test_data_path: data/math/math_cot_test.csv
models: ['gpt4o', 'llama-3.1-405b']

k: 5
batch_size: 50
num_axes_generated: 25
num_eval: 25
embedding_model: text-embedding-3-small
seed: 42
cluster_method: hierarchical
ranker: RelativeRanker

sampler: Sampler
reducer: AxisReducer
proposer: LLMProposerFixed
num_topic_clusters: 5
proposer_batch_size: 5
proposer_only: True
proposer_prompt: proposer_prompt_math_cot

judges: [gpt-4o-mini]
eval_only: False
num_proposal_samples: 20
axes: False
new_prompt: True

new_sample: True

# models
rubric_generation_model: "gpt-4o"
proposer_model: "gpt-4o"