# Path to CSV file containing model outputs. Must include columns for model responses 
# and a 'preference' column indicating which model output was preferred.
data_path: "data/llama3-70b-arena/llama_vs_not_llama_soft_questions.csv"  # Required argument
num_samples: null 

wandb: true # If true, logs results to Weights & Biases.

output_dir: "./vibecheck_results" # Directory to save results.
name: "llama3-70b-arena-soft-questions-axis-preset" # Name of the experiment, used for saving the pkl file.

models: ["llama-3-70b-instruct", "not_llama"]  # List of two model names to compare. These should match the column names in the CSV.

# Name of the Weights & Biases project where results will be logged.
project_name: "vibecheck"

# If true, only runs the vibe proposal step without conducting further analysis.
proposer_only: false

# llm to use for preference judgment (only used if preference column does not exist)
preference_judge_llm: "gpt-4o"

# If true, uses all data for training without creating a separate test set.
# This can be useful for small datasets but may not give reliable accuracy estimates.
no_holdout_set: true

initial_vibes: [
    "Assertiveness: High: Uses definitive, confident statements. Low: Uses tentative or uncertain language.",
    "Detail and Elaboration: High: Provides thorough, nuanced, and expansive information. Low: Gives brief or shallow responses.",
    "Formalness: High: Uses formal and sophisticated vocabulary and sentence structure. Low: Uses casual, conversational, or informal language.",
    "Emotional Tone: High: Infuses responses with expressive emotion, making the tone enthusiastic or empathetic. Low: Remains neutral or detached.",
    "Creativity and Originality: High: Provides responses with novel ideas or imaginative scenarios. Low: Sticks to standard, predictable answers.",
    "Explicitness: High: States things directly and unambiguously. Low: Uses vague or implicit language.",
    "Humor and Playfulness: High: Uses humor, playful language, or wordplay to make the response engaging. Low: Responds in a straightforward and serious manner.",
    "Engagement: High: Actively engages the reader using rhetorical questions or interactive phrasing. Low: Presents information passively.",
    "Logical Rigor: High: Constructs well-supported arguments with clear reasoning. Low: Provides conclusions without thorough justification.",
    "Conciseness: High: Uses minimal words to convey a point clearly. Low: Uses verbose language and excessive details.",
    "Persuasiveness: High: Constructs arguments that are compelling and convincing. Low: Presents information without attempting to persuade.",
    "Bias and Subjectivity: High: Expresses opinions, takes sides, or incorporates bias. Low: Remains neutral and objective.",
    "Clarity and Readability: High: Uses simple, clear, and easily understandable language. Low: Uses complex or convoluted phrasing.",
    "Safety and Sensitivity: High: Avoids controversial, offensive, or harmful language. Low: May include insensitive or risky statements.",
    "Interactivity: High: Encourages user participation (e.g., prompts for feedback). Low: Delivers static information without seeking input.",
    "Novelty vs. Conventionality: High: Offers unconventional, unexpected perspectives. Low: Aligns with mainstream, widely accepted views.",
    "Personalization: High: Appears tailored to the specific input, using relevant details. Low: Provides generic responses without customization.",
    "Visual Structure: High: Uses formatting elements like bullet points, headings, and paragraphing for visual organization. Low: Presents text as dense blocks without visual breaks.",
    "Technical Precision: High: Uses domain-specific terminology accurately. Low: Uses simplified, layperson terms even for technical concepts.",
    "Citation Style: High: Explicitly references sources or authorities. Low: Makes claims without attribution or reference.",
    "Temporal Focus: High: Emphasizes future implications or forward-looking statements. Low: Focuses on present facts or historical context.",
    "Metaphorical Language: High: Uses analogies, metaphors, and figurative language. Low: Uses literal, direct descriptions.",
    "First-Person Voice: High: Uses 'I' statements and personal perspective. Low: Uses third-person or impersonal perspective.",
    "Numerical Precision: High: Provides specific numbers, statistics, or quantitative data. Low: Uses qualitative descriptions without numerical specificity.",
    "Hedging: High: Qualifies statements with caveats and limitations. Low: Makes unqualified statements without acknowledging constraints.",
    "Instructional Tone: High: Provides guidance, steps, or actionable advice. Low: Describes information without suggesting actions.",
    "Cultural Specificity: High: References specific cultural contexts or knowledge. Low: Provides culturally neutral or universalized information."
]

iterations: 3 # Number of iterations to run the analysis. 

proposer:
  # Number of samples to use when proposing vibes. Higher numbers will give more comprehensive but slower results.
  num_samples: 30
  model: "gpt-4o"
  shuffle_positions: false # If true, shuffles the positions of the models in the prompt for finding vibes. This is best when you are using the axis proposal method.
  batch_size: 5 # Number of samples to use for each batch (LLM call) in the vibe proposal.
  embedding_model: "text-embedding-3-small" # Model to use for embedding analysis.
  prompt: proposer_freeform_axis
  iteration_prompt: proposer_freeform_iteration_axis
  reduction_prompt: reduce_freeform_axis

ranker: 
  single_position_rank: false # If true, only ranks model outputs in one position order. This is faster but may introduce position bias in the analysis.
  model: "gpt-4o-mini"
  solver: "elasticnet" # Solver to use for regression analysis (choices: standard, lasso, elasticnet)
  # num_final_vibes: null # Maximum number of vibes to use in final analysis. This limits the number of behavioral dimensions that will be analyzed.
  embedding_model: "text-embedding-3-small" # Model to use for embedding analysis.
  embedding_rank: false # If true, ranks model outputs using embedding similarity. This is much cheaper than the LLM ranker, but way less accurate.
  vibe_batch_size: 5 # batch ranker
  prompt: ranker_prompt_axis_multi # Type of prompt to use for ranker. Found in components/prompts/ranker_prompts.py

filter:
  min_score_diff: 0.05 # Minimum score difference to consider a vibe.
  min_pref_score_diff: 0.05 # Minimum preference score difference to consider a vibe.