project: VibeCheck-Llama-STEM
wandb: False # Set to True to log to Weights and Biases
num_samples: False
output_name: vibecheck_eval_1_iter
num_final_eval: 5

save_dir: pipeline_results
data_path: ../VibeCheck-dev/data/arena/stem/llama_vs_not_llama_stem_train.csv
test_data_path: ../VibeCheck-dev/data/arena/stem/llama_vs_not_llama_stem_test.csv
models: [llama-3-70b-instruct, not_llama]

filter: False
k: 10
num_eval: 10
batch_size: 50
num_axes_generated: 10
embedding_model: text-embedding-3-small
seed: 42
cluster_method: hierarchical 
ranker: RelativeRanker
sampler: Sampler
reducer: AxisReducer
proposer: LLMProposerFixed
num_topic_clusters: 5
proposer_batch_size: 5
# judges: [gpt-3.5-turbo, llama-3-70b]
judges: [gpt-4o-mini]
eval_only: True
new_sample: True
num_proposal_samples: 20
new_prompt: True
max_iterations: 1

axes: [
    "Engagement and Enthusiasm: High: The response exudes enthusiasm and engages the reader, often employing exclamation points, a friendly tone, and casual conversational remarks. Low: The response is more formal, neutral, and factual without engaging language.",
    "Interactivity and Engagement: High: Engaging tone, tutorial-like. Low: Formal, direct tone focused on clarity.",
    "Handling of Uncertain Information: High: Clearly indicates uncertainty or assumptions. Low: States information definitively without disclaimers.",
    "Jargon and Terminology: High: Uses specialized jargon and complex terms. Low: Uses general language and avoids jargon.",
    "Error Handling: High: Includes comprehensive error handling and user input validation within the code. Low: Minimal or no error handling, assumes ideal scenarios.",
    "Safety and Accuracy Emphasis: High: Includes disclaimers, emphasizes ethical considerations. Low: Lacks explicit emphasis on safety or ethics.",
    "Tone and Enthusiasm: High: Engaging, enthusiastic. Low: Neutral, utilitarian.",
    # "Technical Accuracy: High: Accurate, detailed, and precise. Low: Simplified, general, or inaccurate.",
]

proposer_prompt: proposer_prompt_freeform

# models
rubric_generation_model: "gpt-4o"
proposer_model: "gpt-4o"